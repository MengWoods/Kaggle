{"cells":[{"metadata":{"_uuid":"af5191e2569fc88ab5407b9150ff6d8a270dd560"},"cell_type":"markdown","source":"# Prediction with NN\n> 2018-11-15 13:11:49  \n>\n> reference :  https://www.kaggle.com/jamesleslie/titanic-neural-network-for-beginners\n## About the missing values?\n* train's shape is (891, 12), 'Age' has 714 values, 'Cabin' has 204 values, 'Embarked' has 889 values.\n* final_test's shape is (418, 11), \"Age\" has 332 values, 'Fare' has 417 values, 'Cabin' has 91 values.\n\nFilling the missing age using average Title's age. Filling the missing Fare values using average Pclass's fare; Filling the missing embarked value as S.\n\nHavn't filled the missing Embarked. \n\n## Which factors can be used as input?\nCurrently, I used the 'Age','Fare','Parch','SibSp','Pclass','Sex_female','Sex_male',\n                    'Embarked_C','Embarked_Q','Embarked_S'\n\n## Tips\n\n What really helps in this is creating a good cross validation framework so you can get a reliable error estimate\n \n ## Value type\n* Numerical Features: Age, Fare, SibSp and Parch\n* Categorical Features: Sex, Embarked, Survived and Pclass\n* Alphanumeric Features: Ticket and Cabin(Contains both alphabets and the numeric value)\n* Text Features: Name"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf # NN\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split # split train and test set\n\nfrom time import time\nimport os\nprint(os.listdir(\"../input\"))\n\n# read files\npath = '../input'\nfinal_test = pd.read_csv(path + '/test.csv') \ntrain = pd.read_csv(path + '/train.csv')\ndel path\n\npassengerId = final_test['PassengerId']  # hold it for the submission file\n\n# inspect data\nprint('train.shape',train.shape,\n      '\\nfinal_test.shape',final_test.shape)\n\nprint('====train info====')\nprint(train.info())\nprint('====final test info====')\nprint(final_test.info())\n#train.head(20)\n#final_test.head(20)","execution_count":1,"outputs":[{"output_type":"stream","text":"['gender_submission.csv', 'test.csv', 'train.csv']\ntrain.shape (891, 12) \nfinal_test.shape (418, 11)\n====train info====\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\nNone\n====final test info====\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"ce48d06256becce8611b75057c024364aad38932"},"cell_type":"code","source":"# data pre-processing. Since the limited info of cabin, I abandon this column.\n# missing age: use the average age of passenger's Title\n    \n# replace rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n           'Don': 'Mr', 'Mme': 'Miss', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ntitles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\n# function, extract title and creat new column for it, then filling missing age with average\ndef fill_missing_age(data):\n    #extract title, replace rare ones.\n    data[\"Title\"] = data[\"Name\"] # add a new column\n    for name in data[\"Title\"]:\n        data[\"Title\"] = data[\"Name\"].str.extract('([A-Za-z]+)\\.', expand=True)\n    data.replace({'Title': mapping}, inplace=True)\n    # present missing age with median of Title column\n    for title in titles:\n        median = data.groupby('Title')[\"Age\"].median()[titles.index(title)]\n        data.loc[(data['Age'].isnull()) & (data[\"Title\"] == title), 'Age'] = median\n    return data\n\ntrain = fill_missing_age(train)\nfinal_test = fill_missing_age(final_test)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe39a9a708094a8d04d3091fe2800d490ad5aea"},"cell_type":"code","source":"# inspect the average age with Title\ntrain.pivot_table(index='Title',values = 'Age').plot.bar()\nplt.show()\n# the portion of survival with respect to Title\nsurvived = train[train['Survived'] == 1]\ndied = train[train['Survived'] == 0]\nsns.countplot(x='Title',data=train, palette='hls', hue='Survived')\nplt.xticks(rotation=45)\nplt.show()","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3614c55bd0d76a6185fce1f4319649414b61578e"},"cell_type":"code","source":"# For the missing Fare values, using the median fare value of class.\np_classes=[1,2,3]\ndef fill_missing_fare(data):\n    for p_class in p_classes:\n        median_fare = data.groupby('Pclass')['Fare'].median()[p_class]\n        data.loc[(data['Fare'].isnull()) & (data['Pclass'] == p_class),'Fare' ] = median_fare \n    return data\n\ntrain = fill_missing_fare(train)\nfinal_test = fill_missing_fare(final_test)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7634055e68a9ab09164f6abe16f0a8186c91df46"},"cell_type":"code","source":"# filling missing embarked value with S\ntrain = train.fillna({\"Embarked\": \"S\"})","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e991884f2f96a513fb965ed654e5e54231990194"},"cell_type":"code","source":"# Using one hot encoder to perform binarization of the category and include it as a feature\n# convert categorical variables into numeric format\n#categorical = data[['Pclass', 'Sex']].values\n#encoded_vars_temp = []\n\ndef create_dummies(data_df,column_name):\n    for name in column_name:        \n        dummies = pd.get_dummies(data_df[name], prefix=name)\n        data_df = pd.concat([data_df, dummies], axis=1)\n    return data_df\n\ntrain = create_dummies(train,['Pclass','Sex','Embarked'])\nfinal_test = create_dummies(final_test,['Pclass','Sex','Embarked']) \ntrain.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   PassengerId  Survived  Pclass     ...     Embarked_C Embarked_Q  Embarked_S\n0            1         0       3     ...              0          0           1\n1            2         1       1     ...              1          0           0\n2            3         1       3     ...              0          0           1\n3            4         1       1     ...              0          0           1\n4            5         0       3     ...              0          0           1\n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>Mrs</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Miss</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>Mrs</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"2f6717dd39dab73a80da5e17f60a3d3d2523e672","scrolled":true},"cell_type":"code","source":"# Scale continuous variables to values between -1 and 1.\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n\nall_data = train.append(final_test, ignore_index=True)\n\ndef scale_var(df,column_names):\n    scaler = MinMaxScaler(feature_range=(-1.,1.))\n    for name in column_names:\n        var_scaled = scaler.fit_transform(df[[name]])\n        df[name] = var_scaled  \n    return df\nall_data = scale_var(all_data,['Age','Fare','SibSp','Parch'])\n# bring back to two datasets\n#all_data.loc[890:899]\n# refine data. reserve values for inputs and outputs.\nall_data = all_data [['Survived','Age','Fare','Parch','SibSp','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male',\n                    'Embarked_C','Embarked_Q','Embarked_S']]\n\ntrain = all_data[:890]\nfinal_test = all_data[891:]\nall_data","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  sort=sort)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n","name":"stderr"},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"      Survived       Age     ...      Embarked_Q  Embarked_S\n0          0.0 -0.453088     ...               0           1\n1          1.0 -0.052236     ...               0           0\n2          1.0 -0.352875     ...               0           1\n3          1.0 -0.127396     ...               0           1\n4          0.0 -0.127396     ...               0           1\n5          0.0 -0.252662     ...               1           0\n6          0.0  0.348616     ...               0           1\n7          0.0 -0.954153     ...               0           1\n8          1.0 -0.327822     ...               0           1\n9          1.0 -0.653514     ...               0           0\n10         1.0 -0.904046     ...               0           1\n11         1.0  0.448829     ...               0           1\n12         0.0 -0.503194     ...               0           1\n13         0.0 -0.027183     ...               0           1\n14         0.0 -0.653514     ...               0           1\n15         1.0  0.373669     ...               0           1\n16         0.0 -0.954153     ...               1           0\n17         1.0 -0.252662     ...               0           1\n18         0.0 -0.227609     ...               0           1\n19         1.0 -0.127396     ...               0           0\n20         0.0 -0.127396     ...               0           1\n21         1.0 -0.152449     ...               0           1\n22         1.0 -0.628460     ...               1           0\n23         1.0 -0.302768     ...               0           1\n24         0.0 -0.803833     ...               0           1\n25         1.0 -0.052236     ...               0           1\n26         0.0 -0.252662     ...               0           0\n27         0.0 -0.528248     ...               0           1\n28         1.0 -0.465614     ...               1           0\n29         0.0 -0.252662     ...               0           1\n...        ...       ...     ...             ...         ...\n1279       NaN -0.478141     ...               1           0\n1280       NaN -0.853940     ...               0           1\n1281       NaN -0.428035     ...               0           1\n1282       NaN  0.273456     ...               0           1\n1283       NaN -0.678567     ...               0           1\n1284       NaN  0.173243     ...               0           1\n1285       NaN -0.277715     ...               0           1\n1286       NaN -0.553301     ...               0           1\n1287       NaN -0.402981     ...               1           0\n1288       NaN  0.198296     ...               0           0\n1289       NaN -0.453088     ...               0           1\n1290       NaN -0.227609     ...               1           0\n1291       NaN -0.252662     ...               0           1\n1292       NaN -0.052236     ...               0           1\n1293       NaN -0.453088     ...               0           0\n1294       NaN -0.578354     ...               0           1\n1295       NaN  0.073030     ...               0           0\n1296       NaN -0.503194     ...               0           0\n1297       NaN -0.428035     ...               0           1\n1298       NaN  0.248403     ...               0           0\n1299       NaN -0.453088     ...               1           0\n1300       NaN -0.929099     ...               0           1\n1301       NaN -0.453088     ...               1           0\n1302       NaN -0.077289     ...               1           0\n1303       NaN -0.302768     ...               0           1\n1304       NaN -0.277715     ...               0           1\n1305       NaN -0.027183     ...               0           0\n1306       NaN -0.039709     ...               0           1\n1307       NaN -0.277715     ...               0           1\n1308       NaN -0.828886     ...               0           0\n\n[1309 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Parch</th>\n      <th>SibSp</th>\n      <th>Pclass_1</th>\n      <th>Pclass_2</th>\n      <th>Pclass_3</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-0.453088</td>\n      <td>-0.971698</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>-0.052236</td>\n      <td>-0.721729</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-0.352875</td>\n      <td>-0.969063</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.127396</td>\n      <td>-0.792711</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>-0.127396</td>\n      <td>-0.968575</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.0</td>\n      <td>-0.252662</td>\n      <td>-0.966981</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.0</td>\n      <td>0.348616</td>\n      <td>-0.797542</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.0</td>\n      <td>-0.954153</td>\n      <td>-0.917729</td>\n      <td>-0.777778</td>\n      <td>-0.25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>-0.327822</td>\n      <td>-0.956538</td>\n      <td>-0.555556</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>-0.653514</td>\n      <td>-0.882611</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>-0.904046</td>\n      <td>-0.934808</td>\n      <td>-0.777778</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>0.448829</td>\n      <td>-0.896356</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.0</td>\n      <td>-0.503194</td>\n      <td>-0.968575</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.0</td>\n      <td>-0.027183</td>\n      <td>-0.877911</td>\n      <td>0.111111</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.0</td>\n      <td>-0.653514</td>\n      <td>-0.969339</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>0.373669</td>\n      <td>-0.937540</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.0</td>\n      <td>-0.954153</td>\n      <td>-0.886304</td>\n      <td>-0.777778</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1.0</td>\n      <td>-0.252662</td>\n      <td>-0.949251</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.0</td>\n      <td>-0.227609</td>\n      <td>-0.929733</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1.0</td>\n      <td>-0.127396</td>\n      <td>-0.971795</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.0</td>\n      <td>-0.127396</td>\n      <td>-0.898503</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1.0</td>\n      <td>-0.152449</td>\n      <td>-0.949251</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.0</td>\n      <td>-0.628460</td>\n      <td>-0.968656</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1.0</td>\n      <td>-0.302768</td>\n      <td>-0.861417</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.0</td>\n      <td>-0.803833</td>\n      <td>-0.917729</td>\n      <td>-0.777778</td>\n      <td>-0.25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1.0</td>\n      <td>-0.052236</td>\n      <td>-0.877471</td>\n      <td>0.111111</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.0</td>\n      <td>-0.252662</td>\n      <td>-0.971795</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.0</td>\n      <td>-0.528248</td>\n      <td>0.026684</td>\n      <td>-0.555556</td>\n      <td>-0.25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1.0</td>\n      <td>-0.465614</td>\n      <td>-0.969242</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.0</td>\n      <td>-0.252662</td>\n      <td>-0.969177</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1279</th>\n      <td>NaN</td>\n      <td>-0.478141</td>\n      <td>-0.969746</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1280</th>\n      <td>NaN</td>\n      <td>-0.853940</td>\n      <td>-0.917729</td>\n      <td>-0.777778</td>\n      <td>-0.25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1281</th>\n      <td>NaN</td>\n      <td>-0.428035</td>\n      <td>-0.635000</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1282</th>\n      <td>NaN</td>\n      <td>0.273456</td>\n      <td>-0.846193</td>\n      <td>-0.777778</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1283</th>\n      <td>NaN</td>\n      <td>-0.678567</td>\n      <td>-0.920949</td>\n      <td>-0.555556</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1284</th>\n      <td>NaN</td>\n      <td>0.173243</td>\n      <td>-0.959011</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1285</th>\n      <td>NaN</td>\n      <td>-0.277715</td>\n      <td>-0.914020</td>\n      <td>-0.777778</td>\n      <td>-0.25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1286</th>\n      <td>NaN</td>\n      <td>-0.553301</td>\n      <td>-0.765776</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1287</th>\n      <td>NaN</td>\n      <td>-0.402981</td>\n      <td>-0.971698</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1288</th>\n      <td>NaN</td>\n      <td>0.198296</td>\n      <td>-0.690824</td>\n      <td>-0.777778</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1289</th>\n      <td>NaN</td>\n      <td>-0.453088</td>\n      <td>-0.969648</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1290</th>\n      <td>NaN</td>\n      <td>-0.227609</td>\n      <td>-0.969811</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1291</th>\n      <td>NaN</td>\n      <td>-0.252662</td>\n      <td>-0.356403</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1292</th>\n      <td>NaN</td>\n      <td>-0.052236</td>\n      <td>-0.918021</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1293</th>\n      <td>NaN</td>\n      <td>-0.453088</td>\n      <td>-0.768118</td>\n      <td>-0.777778</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>NaN</td>\n      <td>-0.578354</td>\n      <td>-0.816134</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>NaN</td>\n      <td>0.073030</td>\n      <td>-0.891785</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>NaN</td>\n      <td>-0.503194</td>\n      <td>-0.945884</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>NaN</td>\n      <td>-0.428035</td>\n      <td>-0.959011</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>NaN</td>\n      <td>0.248403</td>\n      <td>-0.174359</td>\n      <td>-0.777778</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>NaN</td>\n      <td>-0.453088</td>\n      <td>-0.969860</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1300</th>\n      <td>NaN</td>\n      <td>-0.929099</td>\n      <td>-0.946226</td>\n      <td>-0.777778</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1301</th>\n      <td>NaN</td>\n      <td>-0.453088</td>\n      <td>-0.969746</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1302</th>\n      <td>NaN</td>\n      <td>-0.077289</td>\n      <td>-0.648663</td>\n      <td>-1.000000</td>\n      <td>-0.75</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1303</th>\n      <td>NaN</td>\n      <td>-0.302768</td>\n      <td>-0.969648</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1304</th>\n      <td>NaN</td>\n      <td>-0.277715</td>\n      <td>-0.968575</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>NaN</td>\n      <td>-0.027183</td>\n      <td>-0.574883</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>NaN</td>\n      <td>-0.039709</td>\n      <td>-0.971698</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>NaN</td>\n      <td>-0.277715</td>\n      <td>-0.968575</td>\n      <td>-1.000000</td>\n      <td>-1.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>NaN</td>\n      <td>-0.828886</td>\n      <td>-0.912719</td>\n      <td>-0.777778</td>\n      <td>-0.75</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1309 rows  13 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"426b4226d8eacaf7a740567b95f730055a8c5823"},"cell_type":"code","source":"# split the train to train and test, for cross validation\nfrom sklearn.model_selection import train_test_split\n\n# using train dataset for train and test the performance\ntrain_all_y = train[['Survived']]\ntrain_all_x = train[['Age','Fare','Parch','SibSp','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male',\n                    'Embarked_C','Embarked_Q','Embarked_S']]\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"865f1c5d2ffa4fa916c8482105f14c8c7e892fb3"},"cell_type":"code","source":"# test_size control the proportions of data are split into. Randomly split\ntr_train_X, tr_test_X, tr_train_y, tr_test_y = train_test_split(train_all_x, train_all_y, test_size = 0.4)\n# neural network\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\n# build neural network model\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=tr_train_X.shape[1], activation='relu')) # input layer and hidden layer1 \nmodel.add(Dense(20, activation = 'relu'))\nmodel.add(Dense(15, activation = 'relu'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(1, activation='sigmoid')) # output layer\n# compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n# train model\nmodel.fit(tr_train_X, tr_train_y,epochs=50, batch_size=32)\n# evaluate the model\nscores = model.evaluate(tr_train_X,tr_train_y)\nprint(\"\\n evaluate scores %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n\nprediction = model.evaluate(tr_test_X, tr_test_y)\nprint(\"\\n prediction accuracy %s: %.3f%%\" % (model.metrics_names[1], prediction[1]*100))\n\n#result = model.predict(tr_test_X)\n#r = [round(x[0]) for x in result]\n#y = tr_test_y['Survived'].tolist()\n#diff = 0\n#for i in range(tr_test_y.shape[0]):\n#    diff = abs(r[i] - y[i]) + diff\n#print(\"\\n real acc:\", 1-(diff/tr_test_y.shape[0]) )\n\n#================== Gradient Boosting Classifier====================\n#tr_train_X, tr_test_X, tr_train_y, tr_test_y\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\n\ngbk = GradientBoostingClassifier()\ngbk.fit(tr_train_X, tr_train_y)\ny_pred = gbk.predict(tr_test_X)\nacc_gbk = round(accuracy_score(y_pred, tr_test_y) * 100, 2)\nprint('GradientBoostingClassifier accurate:',acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2691ff69c1edf1dd85d76da5e13ef2f85cb9bdb4"},"cell_type":"code","source":"#Prediction with GBK\ngbk.fit(train_all_x, train_all_y)\nfinal_test_x = final_test[['Age','Fare','Parch','SibSp','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male',\n                    'Embarked_C','Embarked_Q','Embarked_S']]\npredictions = gbk.predict(final_test_x)\npredictions = predictions\nrounded = [round(x) for x in predictions]\nsolution = pd.DataFrame(rounded)\nsolution = solution.astype(int)\nsubmission = pd.concat([passengerId,solution], axis=1)\nsubmission.columns = ['PassengerId','Survived']\nsubmission.to_csv('Titanic_GBK_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce8cb2b50c282d5d7847879c2498240f47a43d0d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfcc8025f20a4856484d47abc898c203e68d2676"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1dbbe8193aa2c9400882ed925f832ea200c45b4"},"cell_type":"code","source":"'''\n# datasets pre-processing finished\n# now split the train dataset to train and test, training neural network\n# apply all train data to fit model\n\n# train model\nmodel.fit(train_all_x,train_all_y,epochs=50, batch_size=32)\n\n# evaluate the model\nscores = model.evaluate(train_all_x,train_all_y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cdf5dbe433e85c3e7baae2e34d4c52fb7c224d0"},"cell_type":"code","source":"'''\n# calculate predictions\nfinal_text_x = final_test[['Age','Fare','Parch','SibSp','Pclass_1','Pclass_2','Pclass_3','Sex_female','Sex_male',\n                    'Embarked_C','Embarked_Q','Embarked_S']]\npredictions = model.predict(final_text_x)\nrounded = [round(x[0]) for x in predictions]\n#rounded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e49cb4c6cb43f5e25f7f663128351d47d22ec2bf"},"cell_type":"code","source":"'''\nsolution = pd.DataFrame(rounded)\nsolution = solution.astype(int)\nsubmission = pd.concat([passengerId,solution], axis=1)\nsubmission.columns = ['PassengerId','Survived']\nsubmission.to_csv('Titanic_NN_4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"243625130ae363f388aa1e33e931ed81bd78370a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c44a1e4f274e16fa514d85542678c5a70cdcfdf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4b673ca398b12a0aff35b99a91e31c6f4dde31"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}